{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB\n",
    "from sklearn.svm import SVC  \n",
    "import random\n",
    "from xgboost import XGBClassifier\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1116, 14)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('google_books.csv')\n",
    "count_one_hot_words = pd.read_csv('count_one_hot_words.csv')\n",
    "tfidf_one_hot_words = pd.read_csv('tfidf_one_hot_words.csv')\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1111, 14)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>subtitle</th>\n",
       "      <th>authors</th>\n",
       "      <th>publisher</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>categories</th>\n",
       "      <th>pageCount</th>\n",
       "      <th>listPrice</th>\n",
       "      <th>images</th>\n",
       "      <th>isEbook</th>\n",
       "      <th>ratingsCount</th>\n",
       "      <th>averageRating</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>The Litigators</td>\n",
       "      <td>NaN</td>\n",
       "      <td>John Grisham</td>\n",
       "      <td>Dell</td>\n",
       "      <td>10</td>\n",
       "      <td>2011</td>\n",
       "      <td>Fiction</td>\n",
       "      <td>496</td>\n",
       "      <td>9.99</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>137</td>\n",
       "      <td>3.5</td>\n",
       "      <td>The partners at Finley &amp; Figg often refer to t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Ragtime</td>\n",
       "      <td>A Novel</td>\n",
       "      <td>E.L. Doctorow</td>\n",
       "      <td>Random House</td>\n",
       "      <td>11</td>\n",
       "      <td>2010</td>\n",
       "      <td>Fiction</td>\n",
       "      <td>336</td>\n",
       "      <td>14.99</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>57</td>\n",
       "      <td>3.5</td>\n",
       "      <td>Selected by the Modern Library as one of the 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Her Perfect Man</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Mary Lynn Baxter</td>\n",
       "      <td>Silhouette</td>\n",
       "      <td>5</td>\n",
       "      <td>2011</td>\n",
       "      <td>Fiction</td>\n",
       "      <td>192</td>\n",
       "      <td>3.99</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>One look at firebrand Katherine Mays and Bryce...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>The Vanished Man</td>\n",
       "      <td>A Lincoln Rhyme Novel</td>\n",
       "      <td>Jeffery Deaver</td>\n",
       "      <td>Simon and Schuster</td>\n",
       "      <td>8</td>\n",
       "      <td>2012</td>\n",
       "      <td>Fiction</td>\n",
       "      <td>577</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>19</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Hunting down a killer and master illusionist w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>One Sunday</td>\n",
       "      <td>A Novel</td>\n",
       "      <td>Carrie Gerlach Cecil</td>\n",
       "      <td>Simon and Schuster</td>\n",
       "      <td>2</td>\n",
       "      <td>2013</td>\n",
       "      <td>Fiction</td>\n",
       "      <td>255</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>When her unborn child's health is put at risk,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              title               subtitle               authors  \\\n",
       "0    The Litigators                    NaN          John Grisham   \n",
       "1           Ragtime                A Novel         E.L. Doctorow   \n",
       "2   Her Perfect Man                    NaN      Mary Lynn Baxter   \n",
       "3  The Vanished Man  A Lincoln Rhyme Novel        Jeffery Deaver   \n",
       "4        One Sunday                A Novel  Carrie Gerlach Cecil   \n",
       "\n",
       "            publisher  month  year categories  pageCount  listPrice  images  \\\n",
       "0                Dell     10  2011    Fiction        496       9.99   False   \n",
       "1        Random House     11  2010    Fiction        336      14.99    True   \n",
       "2          Silhouette      5  2011    Fiction        192       3.99   False   \n",
       "3  Simon and Schuster      8  2012    Fiction        577        NaN   False   \n",
       "4  Simon and Schuster      2  2013    Fiction        255        NaN   False   \n",
       "\n",
       "   isEbook  ratingsCount  averageRating  \\\n",
       "0     True           137            3.5   \n",
       "1     True            57            3.5   \n",
       "2     True             1            5.0   \n",
       "3    False            19            4.0   \n",
       "4    False             6            4.0   \n",
       "\n",
       "                                         description  \n",
       "0  The partners at Finley & Figg often refer to t...  \n",
       "1  Selected by the Modern Library as one of the 1...  \n",
       "2  One look at firebrand Katherine Mays and Bryce...  \n",
       "3  Hunting down a killer and master illusionist w...  \n",
       "4  When her unborn child's health is put at risk,...  "
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dropna(subset=['description'], inplace=True)\n",
    "df.reset_index(inplace=True, drop=True)\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "## target feature indicating if book gets a 4.5 rating or above\n",
    "def above4p5(x):\n",
    "    if x >= 4.5:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "df['above4p5'] = df['averageRating'].map(lambda x: above4p5(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n"
     ]
    }
   ],
   "source": [
    "## make feature that indicates if popular or unpopular author \n",
    "## i.e. does the author appear more than once \n",
    "author_count = df.authors.value_counts()\n",
    "popular_authors = list(author_count[author_count >= 3].index)\n",
    "\n",
    "def popular_author(x):\n",
    "    if x in popular_authors:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "df['popular_author'] = df['authors'].map(lambda x: popular_author(x))\n",
    "print(df['popular_author'].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A&amp;C Black</th>\n",
       "      <th>A&amp;amp;C Black</th>\n",
       "      <th>Abrams</th>\n",
       "      <th>Academic Press</th>\n",
       "      <th>Acculant Publishing</th>\n",
       "      <th>Ace</th>\n",
       "      <th>Addison-Wesley</th>\n",
       "      <th>Addison-Wesley Professional</th>\n",
       "      <th>Adelphi Edizioni spa</th>\n",
       "      <th>African Books Collective</th>\n",
       "      <th>...</th>\n",
       "      <th>year</th>\n",
       "      <th>guide</th>\n",
       "      <th>readers</th>\n",
       "      <th>recipes</th>\n",
       "      <th>man</th>\n",
       "      <th>novel</th>\n",
       "      <th>students</th>\n",
       "      <th>just</th>\n",
       "      <th>real</th>\n",
       "      <th>design</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 465 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   A&C Black  A&amp;C Black  Abrams  Academic Press  Acculant Publishing  Ace  \\\n",
       "0          0              0       0               0                    0    0   \n",
       "1          0              0       0               0                    0    0   \n",
       "2          0              0       0               0                    0    0   \n",
       "3          0              0       0               0                    0    0   \n",
       "4          0              0       0               0                    0    0   \n",
       "\n",
       "   Addison-Wesley  Addison-Wesley Professional  Adelphi Edizioni spa  \\\n",
       "0               0                            0                     0   \n",
       "1               0                            0                     0   \n",
       "2               0                            0                     0   \n",
       "3               0                            0                     0   \n",
       "4               0                            0                     0   \n",
       "\n",
       "   African Books Collective  ...  year  guide  readers  recipes  man  novel  \\\n",
       "0                         0  ...     0      0        0        0    0      1   \n",
       "1                         0  ...     0      0        0        0    0      1   \n",
       "2                         0  ...     0      0        0        0    0      0   \n",
       "3                         0  ...     0      0        0        0    0      0   \n",
       "4                         0  ...     0      0        0        0    0      0   \n",
       "\n",
       "   students  just  real  design  \n",
       "0         0     0     0       0  \n",
       "1         0     0     1       0  \n",
       "2         0     0     0       0  \n",
       "3         0     0     0       0  \n",
       "4         0     0     0       0  \n",
       "\n",
       "[5 rows x 465 columns]"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = tfidf_one_hot_words.iloc[:,0:49]\n",
    "\n",
    "df = pd.concat([ pd.get_dummies(df['publisher']), pd.get_dummies(df['month']), \n",
    "                     pd.get_dummies(df['year']), pd.get_dummies(df['categories']), \n",
    "                df['images'], df['isEbook'], df['popular_author'], df['above4p5']], axis=1)\n",
    "df = pd.concat([df, words], join=\"inner\", axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Solving imbalances in the train test split due to uneven distribution of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## this cell makes a train-test-split based on dataframe index\n",
    "## it is taking random samples of words (column) and splitting it into a mini\n",
    "## train-test dataframe then merging to a running tally of random samples\n",
    "## once the running tally reaches approximately 75% of the main dataframe,\n",
    "## the loop halts\n",
    "freq_words = words.apply(np.sum, axis=0)\n",
    "\n",
    "## initialze empty dataframes\n",
    "train = pd.DataFrame(columns = df.columns)\n",
    "test = pd.DataFrame(columns = df.columns)\n",
    "\n",
    "## while loop until train dataframe reaches 75% of main df n_rows\n",
    "while train.shape[0] <= round(len(df.index) * 0.75):\n",
    "    ## sample a word and split in to train/test based on the word\n",
    "    samp = freq_words[freq_words<100].sample(1).index[0]\n",
    "    col = tfidf_one_hot_words[[samp]]\n",
    "\n",
    "    ## gets all the rows where that word occurs\n",
    "    col = col[col[samp]==1]\n",
    "\n",
    "    ## estimate of how many rows we want in micro train dataset\n",
    "    n_train = round(len(col.index) * 0.75)\n",
    "\n",
    "    ## get a sample of the indices that go in to the micro train dataset\n",
    "    inds = random.sample(range(0,len(col.index)), k=n_train)\n",
    "    train_inds = [list(col.index)[ind] for ind in inds]\n",
    "\n",
    "    ## gtakes difference between train indices and micro dataframe indices to get test in  dices\n",
    "    test_inds = list(set(list(col.index))- set(train_inds))\n",
    "\n",
    "    ## join the micro indices with the macro indices, which we will continue to add to\n",
    "    train = pd.concat([train, df.iloc[train_inds]])\n",
    "    test = pd.concat([test, df.iloc[test_inds]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(865, 465)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A&amp;C Black</th>\n",
       "      <th>A&amp;amp;C Black</th>\n",
       "      <th>Abrams</th>\n",
       "      <th>Academic Press</th>\n",
       "      <th>Acculant Publishing</th>\n",
       "      <th>Ace</th>\n",
       "      <th>Addison-Wesley</th>\n",
       "      <th>Addison-Wesley Professional</th>\n",
       "      <th>Adelphi Edizioni spa</th>\n",
       "      <th>African Books Collective</th>\n",
       "      <th>...</th>\n",
       "      <th>year</th>\n",
       "      <th>guide</th>\n",
       "      <th>readers</th>\n",
       "      <th>recipes</th>\n",
       "      <th>man</th>\n",
       "      <th>novel</th>\n",
       "      <th>students</th>\n",
       "      <th>just</th>\n",
       "      <th>real</th>\n",
       "      <th>design</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1008</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>965</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>967</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>993</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1010</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 465 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     A&C Black A&amp;C Black Abrams Academic Press Acculant Publishing Ace  \\\n",
       "1008         0             0      0              0                   0   0   \n",
       "965          0             0      0              0                   0   0   \n",
       "967          0             0      0              0                   0   0   \n",
       "993          0             0      0              0                   0   0   \n",
       "1010         0             0      0              0                   0   0   \n",
       "\n",
       "     Addison-Wesley Addison-Wesley Professional Adelphi Edizioni spa  \\\n",
       "1008              0                           0                    0   \n",
       "965               0                           0                    0   \n",
       "967               0                           0                    0   \n",
       "993               0                           0                    0   \n",
       "1010              0                           0                    0   \n",
       "\n",
       "     African Books Collective  ... year guide readers recipes man novel  \\\n",
       "1008                        0  ...    0     0       0       1   0     0   \n",
       "965                         0  ...    0     0       0       1   0     0   \n",
       "967                         0  ...    0     0       1       1   0     0   \n",
       "993                         0  ...    0     0       0       1   0     0   \n",
       "1010                        0  ...    0     0       0       1   0     0   \n",
       "\n",
       "     students just real design  \n",
       "1008        0    0    0      0  \n",
       "965         0    1    0      0  \n",
       "967         0    0    0      0  \n",
       "993         0    0    0      0  \n",
       "1010        0    1    0      1  \n",
       "\n",
       "[5 rows x 465 columns]"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(train.shape)\n",
    "train.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "## manually making the train-test-split\n",
    "X_train = train.drop(['above4p5'], axis=1)\n",
    "y_train = train[['above4p5']]\n",
    "\n",
    "X_test = test.drop(['above4p5'], axis=1)\n",
    "y_test = test[['above4p5']]\n",
    "                     \n",
    "# x_sub = X_train.drop([''])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train=y_train.astype('int')\n",
    "y_test = y_test.astype('int')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.set(style='dark', context='talk')\n",
    "palette = sns.color_palette(\"PuBuGn_r\")\n",
    "\n",
    "f, ax = plt.subplots(figsize=(10,8))\n",
    "f.suptitle('Book Ratings', ha='center', fontsize=32)\n",
    "ax = sns.countplot(df['above4p5'], data=df, palette=palette)\n",
    "ax.set_xlabel('')\n",
    "ax.set_xticklabels(['Below 4.5', '4.5 or Above'], fontsize=16)\n",
    "ax.set_ylabel('Number of Books', rotation=270, fontsize=12)\n",
    "ax.yaxis.set_label_position('right')\n",
    "ax.yaxis.set_label_coords(1.095, 0.5)\n",
    "ax.yaxis.tick_right()\n",
    "f.tight_layout(rect=[0, 0.03, 1, 0.95])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted values: \n",
      " [0 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 0 0 1 1 1 1 0 1 1 0 1 1 0 1 1 1 1 1 0 1 1\n",
      " 1 1 1 0 0 0 0 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 0 1 0 1 0 1 1 1 1 1 0 1 1 0\n",
      " 1 1 1 1 1 1 0 0 0 0 1 1 1 1 0 0 1 1 0 1 0 1 1 1 0 0 0 1 1 1 1 1 1 1 1 1 1\n",
      " 1 0 0 1 0 1 0 0 1 1 1 1 1 1 1 0 1 1 1 0 1 0 0 1 1 0 1 1 1 1 0 0 1 0 1 1 0\n",
      " 1 1 1 0 1 0 1 1 1 1 1 0 1 0 1 0 0 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 0 1 0 0 0 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 1 0 1 0 1 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 1 1 1 0 1 1 0 1 1 0 0 1 0 0 1 0 0 0 1 1 1 0 0 1 0 1 0 1 1 0 1 0\n",
      " 1 1 0 1 0 1 0 1 0 1 0 1 0 0 0 1 1 0 0 1 1 1 0 1 1 0 1 1 0 0 1 1 1 1 1 1 1\n",
      " 1 1 1 0 1 1 0 1 0 1 1 0 1 0 1 1 0 1 1 1 0 0 1 1 1 1 0 0 1 0 1 1 0 0 1 1 0\n",
      " 0 0 0 1 0 1 0 1 1 1 0 1 1 0 1 1 0 1 0 1 1 1 0 1 1 1 1 1 0 1 1 1 1 0 0 1 1\n",
      " 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 0 1 0 1 1 0 1 1 0 0 1 0 1 1\n",
      " 1 0 1 0 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 0 1 1 0 1 0 1 0 0 1 1 0 1 0\n",
      " 1 1 1 1 1 1 0 0 1 1 0 1 1 1 0 1 1 0 0 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1\n",
      " 1 1 0 1 0 1 0 1 0 1 1 1 1 0 0 1 1 0 0 1 1 1 1 1 1 1 0 1 1 1 0 1 0 1 1 1 0\n",
      " 0 0 0 1 1 1 0 1 1 0 1 0 1 1 1 1 1 1 0 1 1 0 1 0 1 0 1 1 0 1 1 1 0 1 1 1 1\n",
      " 1 0 1 1 1 0 0 1 1 1 1 0 0 1 1 0 1 1 1 0 0 1 1 0 0 0 1 1 0 1 1 0 0 1 0 0 0\n",
      " 1 0 1 0 1 1 0 0 1 0 0 0 0 1 0 0 1 0 1 0 1 1 1 0 0 1 0 1 0 0 1 1 1 1 1 0 0\n",
      " 0 0 1 0 0 0 1 0 0 1 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 1 1 0 1 1 0 0 1 1 1 0 1 1 1 1 1 1 0 0 1\n",
      " 1 1 0 1 1 1 0 1 1 1 0 0 1 1 0 0 1 0 1 1 1 0 1 1 0 1 0 1 0 1 1 0 1 1 1 1 0\n",
      " 0 1 1 1 1 1 1 1 0 1 0 0 0 1 1 1 1 1 0 1 0 1 0 0 1 0 1 1 1 0 0 0 1 0 1 1 1\n",
      " 1 1 1 0 1 1 0 1 1 1 0 1 1 1] \n",
      "\n",
      "Probability predctions: \n",
      " [[0.62631416 0.37368584]\n",
      " [0.12151091 0.87848909]\n",
      " [0.12828236 0.87171764]\n",
      " ...\n",
      " [0.07978758 0.92021242]\n",
      " [0.14554429 0.85445571]\n",
      " [0.12692351 0.87307649]] \n",
      "\n",
      "Train score: \n",
      " 0.8543352601156069 \n",
      "\n",
      "Test score: \n",
      " 0.8075601374570447\n"
     ]
    }
   ],
   "source": [
    "## logistic regression without word vectors\n",
    "# X = pd.concat([count_one_hot_words], axis=1)\n",
    "# y = df['above4p5']\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state=0)\n",
    "clf = LogisticRegression(random_state=0).fit(X_train, y_train)\n",
    "print(f'Predicted values: \\n {clf.predict(X_train)} \\n')\n",
    "print(f'Probability predctions: \\n {clf.predict_proba(X_train)} \\n')\n",
    "print(f'Train score: \\n {clf.score(X_train, y_train)} \\n')\n",
    "print(f'Test score: \\n {clf.score(X_test, y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     A&C Black A&amp;C Black Abrams Academic Press Acculant Publishing Ace  \\\n",
      "1008         0             0      0              0                   0   0   \n",
      "965          0             0      0              0                   0   0   \n",
      "967          0             0      0              0                   0   0   \n",
      "993          0             0      0              0                   0   0   \n",
      "1010         0             0      0              0                   0   0   \n",
      "...        ...           ...    ...            ...                 ...  ..   \n",
      "888          0             0      0              0                   0   0   \n",
      "869          0             0      0              0                   0   0   \n",
      "675          0             0      0              0                   0   0   \n",
      "878          0             0      0              0                   0   0   \n",
      "764          0             0      0              0                   0   0   \n",
      "\n",
      "     Addison-Wesley Addison-Wesley Professional Adelphi Edizioni spa  \\\n",
      "1008              0                           0                    0   \n",
      "965               0                           0                    0   \n",
      "967               0                           0                    0   \n",
      "993               0                           0                    0   \n",
      "1010              0                           0                    0   \n",
      "...             ...                         ...                  ...   \n",
      "888               0                           0                    0   \n",
      "869               0                           0                    0   \n",
      "675               0                           0                    0   \n",
      "878               0                           0                    0   \n",
      "764               0                           0                    0   \n",
      "\n",
      "     African Books Collective  ... year guide readers recipes man novel  \\\n",
      "1008                        0  ...    0     0       0       1   0     0   \n",
      "965                         0  ...    0     0       0       1   0     0   \n",
      "967                         0  ...    0     0       1       1   0     0   \n",
      "993                         0  ...    0     0       0       1   0     0   \n",
      "1010                        0  ...    0     0       0       1   0     0   \n",
      "...                       ...  ...  ...   ...     ...     ...  ..   ...   \n",
      "888                         0  ...    0     0       0       0   0     0   \n",
      "869                         0  ...    0     1       0       0   0     0   \n",
      "675                         0  ...    0     1       1       0   0     0   \n",
      "878                         0  ...    0     0       0       0   0     0   \n",
      "764                         0  ...    0     0       0       0   0     0   \n",
      "\n",
      "     students just real design  \n",
      "1008        0    0    0      0  \n",
      "965         0    1    0      0  \n",
      "967         0    0    0      0  \n",
      "993         0    0    0      0  \n",
      "1010        0    1    0      1  \n",
      "...       ...  ...  ...    ...  \n",
      "888         0    0    0      0  \n",
      "869         0    0    0      0  \n",
      "675         0    1    0      0  \n",
      "878         0    0    0      0  \n",
      "764         0    0    0      0  \n",
      "\n",
      "[865 rows x 464 columns]\n",
      "Predicted values: \n",
      " [0 1 1 0 1 0 1 0 1 1 1 1 1 1 1 1 0 0 1 1 1 1 0 1 1 0 1 1 0 1 1 1 1 1 0 1 1\n",
      " 1 0 1 0 0 0 0 1 1 0 1 1 1 0 0 0 1 1 0 1 1 1 1 0 1 0 1 0 1 1 1 1 1 0 1 1 0\n",
      " 1 1 1 1 1 1 0 0 0 0 1 1 1 1 0 0 1 1 0 1 0 1 1 1 0 0 0 1 1 1 1 1 1 1 1 1 1\n",
      " 0 0 0 1 0 1 0 0 1 1 0 1 1 1 1 0 1 1 1 0 1 0 0 1 1 0 1 1 1 0 0 0 1 0 1 1 0\n",
      " 0 1 1 0 1 0 1 1 1 0 1 0 1 1 1 1 0 1 1 0 0 1 1 1 0 1 1 1 0 1 0 1 1 0 1 1 1\n",
      " 1 1 1 1 0 0 0 0 0 0 1 0 0 0 0 0 1 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 0 1 1 0 0\n",
      " 0 0 0 0 1 1 0 0 1 0 0 0 0 0 1 1 0 1 1 0 0 0 1 0 1 0 0 1 0 0 1 0 0 0 1 0 0\n",
      " 1 0 0 0 0 1 1 0 0 1 1 0 0 1 0 0 1 0 0 1 0 1 0 1 1 1 0 0 1 0 1 0 0 0 0 1 0\n",
      " 1 1 0 1 1 1 1 0 1 1 0 1 0 0 0 1 1 0 1 0 1 1 0 1 1 0 1 1 0 0 1 1 1 1 1 1 1\n",
      " 1 1 1 0 1 1 0 0 0 1 1 0 1 0 1 1 0 1 1 1 0 0 1 1 1 1 0 0 1 0 0 1 0 0 1 0 1\n",
      " 0 0 0 1 1 1 1 1 1 1 0 1 1 0 1 1 0 1 0 0 0 1 0 0 1 1 1 1 1 0 1 1 1 0 1 1 1\n",
      " 0 1 1 0 1 1 0 1 1 1 1 1 0 0 1 1 1 1 1 1 1 0 1 0 1 0 1 0 0 1 1 0 0 1 0 1 1\n",
      " 1 0 1 0 0 0 1 0 1 0 0 1 1 1 1 1 0 1 1 1 0 1 1 0 1 1 0 1 0 1 0 0 1 1 0 1 0\n",
      " 1 1 1 1 1 0 0 0 1 1 0 1 1 1 0 1 1 0 0 1 1 1 1 1 0 1 1 1 0 1 1 1 1 0 1 1 0\n",
      " 1 1 0 1 0 1 0 1 0 1 1 0 1 0 0 1 0 0 0 1 1 1 1 1 1 1 0 1 1 1 0 1 0 1 1 1 0\n",
      " 0 0 0 1 1 0 0 1 1 0 1 0 1 0 1 1 1 1 0 0 1 0 1 1 1 0 1 1 0 1 0 1 0 1 1 0 0\n",
      " 1 1 1 1 1 0 0 1 1 1 1 1 0 1 1 0 0 0 1 0 1 1 1 1 1 0 0 1 0 1 1 0 1 1 1 1 1\n",
      " 1 0 1 0 1 1 0 0 1 0 0 0 1 1 0 0 1 0 1 0 0 1 1 0 0 1 0 1 1 0 1 1 0 1 0 0 0\n",
      " 0 0 1 0 0 1 1 1 0 1 1 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1 0 0 0 0 1 1 0 0 1 1 1 0 1 1 1 1 1 1 0 0 0\n",
      " 0 1 0 0 0 1 1 1 1 0 0 0 1 1 1 0 0 0 1 0 1 0 1 1 1 1 0 1 0 1 1 0 1 1 1 1 1\n",
      " 0 1 1 1 1 0 1 1 0 1 0 0 0 1 1 0 1 1 0 1 0 0 0 1 1 0 1 1 1 0 0 0 1 0 0 1 1\n",
      " 1 1 1 0 1 1 0 1 1 1 0 1 1 1] \n",
      "\n",
      "Probability pridctions: \n",
      " [[1.  0. ]\n",
      " [0.  1. ]\n",
      " [0.  1. ]\n",
      " ...\n",
      " [0.1 0.9]\n",
      " [0.  1. ]\n",
      " [0.  1. ]] \n",
      "\n",
      "Train score: \n",
      " 0.9965317919075144 \n",
      "\n",
      "Test score: \n",
      " 0.9037800687285223\n"
     ]
    }
   ],
   "source": [
    "## random forest without word vectors\n",
    "\n",
    "# param_grid = {\n",
    "#     'criterion': ['gini', 'entropy'],\n",
    "#     'max_depth': [1, 2, 5, 10, 15, 20],\n",
    "#     'min_samples_split': [2, 5, 10, 15, 20]\n",
    "# }\n",
    "\n",
    "# grid_random_forest = GridSearchCV(RandomForestClassifier(), param_grid, cv=3)\n",
    "# grid_random_forest.fit(X_train, y_train)\n",
    "\n",
    "clf = RandomForestClassifier()\n",
    "print(X_train)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print(f'Predicted values: \\n {clf.predict(X_train)} \\n')\n",
    "print(f'Probability pridctions: \\n {clf.predict_proba(X_train)} \\n')\n",
    "print(f'Train score: \\n {clf.score(X_train, y_train)} \\n')\n",
    "print(f'Test score: \\n {clf.score(X_test, y_test)}')\n",
    "\n",
    "# print(f'Parameters: \\n {grid_random_forest.best_params_} \\n')\n",
    "# print(f'Train score: \\n {grid_random_forest.best_score_} \\n')\n",
    "# print(f'Test score: \\n {grid_random_forest.score(X_test, y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Shape of passed values is (464, 1), indices imply (815, 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mcreate_block_manager_from_blocks\u001b[0;34m(blocks, axes)\u001b[0m\n\u001b[1;32m   1680\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1681\u001b[0;31m         \u001b[0mmgr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBlockManager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1682\u001b[0m         \u001b[0mmgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_consolidate_inplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, blocks, axes, do_integrity_check)\u001b[0m\n\u001b[1;32m    142\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdo_integrity_check\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_verify_integrity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36m_verify_integrity\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    344\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_verify_integrity\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mmgr_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m                 \u001b[0mconstruction_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtot_items\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mtot_items\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mconstruction_error\u001b[0;34m(tot_items, block_shape, axes, e)\u001b[0m\n\u001b[1;32m   1718\u001b[0m     raise ValueError(\n\u001b[0;32m-> 1719\u001b[0;31m         \u001b[0;34m\"Shape of passed values is {0}, indices imply {1}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpassed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimplied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1720\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Shape of passed values is (464, 1), indices imply (815, 1)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-194-b121e8e95355>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m feature_importances = pd.DataFrame(clf.feature_importances_,\n\u001b[1;32m      2\u001b[0m                                    \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m                                    columns=['importance']).sort_values('importance', ascending=False)\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    438\u001b[0m                 \u001b[0mmgr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minit_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m                 \u001b[0mmgr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minit_ndarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m         \u001b[0;31m# For data is list-like, or Iterable (will consume into list)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36minit_ndarray\u001b[0;34m(values, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    211\u001b[0m         \u001b[0mblock_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcreate_block_manager_from_blocks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mcreate_block_manager_from_blocks\u001b[0;34m(blocks, axes)\u001b[0m\n\u001b[1;32m   1686\u001b[0m         \u001b[0mblocks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"values\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mblocks\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1687\u001b[0m         \u001b[0mtot_items\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mblocks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1688\u001b[0;31m         \u001b[0mconstruction_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtot_items\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblocks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mconstruction_error\u001b[0;34m(tot_items, block_shape, axes, e)\u001b[0m\n\u001b[1;32m   1717\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Empty data passed with indices specified.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1718\u001b[0m     raise ValueError(\n\u001b[0;32m-> 1719\u001b[0;31m         \u001b[0;34m\"Shape of passed values is {0}, indices imply {1}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpassed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimplied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1720\u001b[0m     )\n\u001b[1;32m   1721\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Shape of passed values is (464, 1), indices imply (815, 1)"
     ]
    }
   ],
   "source": [
    "feature_importances = pd.DataFrame(clf.feature_importances_,\n",
    "                                   index = X.columns,\n",
    "                                   columns=['importance']).sort_values('importance', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>images</td>\n",
       "      <td>0.032557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Fiction</td>\n",
       "      <td>0.031378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>isEbook</td>\n",
       "      <td>0.025600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Religion</td>\n",
       "      <td>0.020970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.020129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>The Battle Cry Christian Ministries</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Grupo Nelson</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Grupo Editorial Patria</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Doubleday Books</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Bearmanor Media</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>415 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     importance\n",
       "images                                 0.032557\n",
       "Fiction                                0.031378\n",
       "isEbook                                0.025600\n",
       "Religion                               0.020970\n",
       "1                                      0.020129\n",
       "...                                         ...\n",
       "The Battle Cry Christian Ministries    0.000000\n",
       "Grupo Nelson                           0.000000\n",
       "Grupo Editorial Patria                 0.000000\n",
       "Doubleday Books                        0.000000\n",
       "Bearmanor Media                        0.000000\n",
       "\n",
       "[415 rows x 1 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters: \n",
      " {'criterion': 'entropy', 'max_depth': 20, 'min_samples_split': 2} \n",
      "\n",
      "Train score: \n",
      " 0.869364161849711 \n",
      "\n",
      "Test score: \n",
      " 0.9072164948453608\n"
     ]
    }
   ],
   "source": [
    "## with grid search\n",
    "\n",
    "param_grid = {\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_depth': [1, 2, 5, 10, 15, 20],\n",
    "    'min_samples_split': [2, 5, 10, 15, 20]\n",
    "}\n",
    "\n",
    "grid_random_forest = GridSearchCV(RandomForestClassifier(), param_grid, cv=3)\n",
    "grid_random_forest.fit(X_train, y_train)\n",
    "\n",
    "print(f'Parameters: \\n {grid_random_forest.best_params_} \\n')\n",
    "print(f'Train score: \\n {grid_random_forest.best_score_} \\n')\n",
    "print(f'Test score: \\n {grid_random_forest.score(X_test, y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters: \n",
      " {'criterion': 'entropy', 'max_depth': 20, 'min_samples_split': 15} \n",
      "\n",
      "Train score: \n",
      " 0.6446578631452581 \n",
      "\n",
      "Test score: \n",
      " 0.5899280575539568\n"
     ]
    }
   ],
   "source": [
    "## added tfidf_vect bag of words to the model\n",
    "\n",
    "param_grid = {\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_depth': [1, 2, 5, 10, 15, 20],\n",
    "    'min_samples_split': [2, 5, 10, 15, 20]\n",
    "}\n",
    "\n",
    "grid_random_forest = GridSearchCV(RandomForestClassifier(), param_grid, cv=3)\n",
    "grid_random_forest.fit(X_train, y_train)\n",
    "\n",
    "print(f'Parameters: \\n {grid_random_forest.best_params_} \\n')\n",
    "print(f'Train score: \\n {grid_random_forest.best_score_} \\n')\n",
    "print(f'Test score: \\n {grid_random_forest.score(X_test, y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: \n",
      " 0.8126436781609195 \n",
      "\n",
      "Test score: \n",
      " 0.6804123711340206\n"
     ]
    }
   ],
   "source": [
    "## AdaBoost without word vectors\n",
    "clf = AdaBoostClassifier(n_estimators=100, random_state=0)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print(f'Train score: \\n {clf.score(X_train, y_train)} \\n')\n",
    "print(f'Test score: \\n {clf.score(X_test, y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Gradient Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Metrics\n",
      "Model: Gradient Boosted Trees\n",
      "Accuracy: 0.8647398843930636\n",
      "F1-Score: 0.8831168831168832\n",
      "Testing Metrics\n",
      "Model: Gradient Boosted Trees\n",
      "Accuracy: 0.852233676975945\n",
      "F1-Score: 0.8739002932551319\n"
     ]
    }
   ],
   "source": [
    "gbt_clf = GradientBoostingClassifier()\n",
    "gbt_clf.fit(X_train, y_train)\n",
    "\n",
    "gbt_clf_train_preds = gbt_clf.predict(X_train)\n",
    "gbt_clf_test_preds = gbt_clf.predict(X_test)\n",
    "\n",
    "def display_acc_and_f1_score(true, preds, model_name):\n",
    "    acc = accuracy_score(true, preds)\n",
    "    f1 = f1_score(true, preds)\n",
    "    print(\"Model: {}\".format(model_name))\n",
    "    print(\"Accuracy: {}\".format(acc))\n",
    "    print(\"F1-Score: {}\".format(f1))\n",
    "    \n",
    "print(\"Training Metrics\")\n",
    "display_acc_and_f1_score(y_train, gbt_clf_train_preds, model_name='Gradient Boosted Trees')\n",
    "print(\"Testing Metrics\")\n",
    "display_acc_and_f1_score(y_test, gbt_clf_test_preds, model_name='Gradient Boosted Trees')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "sequence item 370: expected str instance, int found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-191-17f7f90d73b8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mXGBClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtraining_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtest_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, callbacks)\u001b[0m\n\u001b[1;32m    724\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    725\u001b[0m             train_dmatrix = DMatrix(X, label=training_labels,\n\u001b[0;32m--> 726\u001b[0;31m                                     missing=self.missing, nthread=self.n_jobs)\n\u001b[0m\u001b[1;32m    727\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    728\u001b[0m         self._Booster = train(xgb_options, train_dmatrix, self.get_num_boosting_rounds(),\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, label, missing, weight, silent, feature_names, feature_types, nthread)\u001b[0m\n\u001b[1;32m    378\u001b[0m         data, feature_names, feature_types = _maybe_pandas_data(data,\n\u001b[1;32m    379\u001b[0m                                                                 \u001b[0mfeature_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 380\u001b[0;31m                                                                 feature_types)\n\u001b[0m\u001b[1;32m    381\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m         data, feature_names, feature_types = _maybe_dt_data(data,\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36m_maybe_pandas_data\u001b[0;34m(data, feature_names, feature_types)\u001b[0m\n\u001b[1;32m    237\u001b[0m         msg = \"\"\"DataFrame.dtypes for data must be int, float or bool.\n\u001b[1;32m    238\u001b[0m                 Did not expect the data types in fields \"\"\"\n\u001b[0;32m--> 239\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m', '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbad_fields\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfeature_names\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: sequence item 370: expected str instance, int found"
     ]
    }
   ],
   "source": [
    "clf = XGBClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "training_preds = clf.predict(X_train)\n",
    "test_preds = clf.predict(X_test)\n",
    "\n",
    "training_accuracy = accuracy_score(y_train, training_preds)\n",
    "test_accuracy = accuracy_score(y_test, test_preds)\n",
    "\n",
    "print('Training Accuracy: {training_accuracy})\n",
    "print('Validation accuracy: {test_accuracy})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A&amp;C Black</th>\n",
       "      <th>A&amp;amp;C Black</th>\n",
       "      <th>Abrams</th>\n",
       "      <th>Academic Press</th>\n",
       "      <th>Acculant Publishing</th>\n",
       "      <th>Ace</th>\n",
       "      <th>Addison-Wesley</th>\n",
       "      <th>Addison-Wesley Professional</th>\n",
       "      <th>Adelphi Edizioni spa</th>\n",
       "      <th>African Books Collective</th>\n",
       "      <th>...</th>\n",
       "      <th>year</th>\n",
       "      <th>guide</th>\n",
       "      <th>readers</th>\n",
       "      <th>recipes</th>\n",
       "      <th>man</th>\n",
       "      <th>novel</th>\n",
       "      <th>students</th>\n",
       "      <th>just</th>\n",
       "      <th>real</th>\n",
       "      <th>design</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>76</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>405</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>155</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>888</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>869</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>675</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>878</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>764</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>668 rows × 464 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    A&C Black A&amp;C Black Abrams Academic Press Acculant Publishing Ace  \\\n",
       "370         0             0      0              0                   0   0   \n",
       "160         0             0      0              0                   0   0   \n",
       "76          0             0      0              0                   0   0   \n",
       "405         0             0      0              0                   0   0   \n",
       "155         0             0      0              0                   0   0   \n",
       "..        ...           ...    ...            ...                 ...  ..   \n",
       "888         0             0      0              0                   0   0   \n",
       "869         0             0      0              0                   0   0   \n",
       "675         0             0      0              0                   0   0   \n",
       "878         0             0      0              0                   0   0   \n",
       "764         0             0      0              0                   0   0   \n",
       "\n",
       "    Addison-Wesley Addison-Wesley Professional Adelphi Edizioni spa  \\\n",
       "370              0                           0                    0   \n",
       "160              0                           0                    0   \n",
       "76               0                           0                    0   \n",
       "405              0                           0                    0   \n",
       "155              0                           0                    0   \n",
       "..             ...                         ...                  ...   \n",
       "888              0                           0                    0   \n",
       "869              0                           0                    0   \n",
       "675              0                           0                    0   \n",
       "878              0                           0                    0   \n",
       "764              0                           0                    0   \n",
       "\n",
       "    African Books Collective  ... year guide readers recipes man novel  \\\n",
       "370                        0  ...    0     0       0       0   1     0   \n",
       "160                        0  ...    0     0       0       0   1     1   \n",
       "76                         0  ...    0     0       0       0   1     0   \n",
       "405                        0  ...    0     0       0       0   1     0   \n",
       "155                        0  ...    0     0       0       0   1     0   \n",
       "..                       ...  ...  ...   ...     ...     ...  ..   ...   \n",
       "888                        0  ...    0     0       0       0   0     0   \n",
       "869                        0  ...    0     1       0       0   0     0   \n",
       "675                        0  ...    0     1       1       0   0     0   \n",
       "878                        0  ...    0     0       0       0   0     0   \n",
       "764                        0  ...    0     0       0       0   0     0   \n",
       "\n",
       "    students just real design  \n",
       "370        0    0    0      0  \n",
       "160        0    0    0      0  \n",
       "76         0    1    0      0  \n",
       "405        0    0    0      0  \n",
       "155        0    0    0      0  \n",
       "..       ...  ...  ...    ...  \n",
       "888        0    0    0      0  \n",
       "869        0    0    0      0  \n",
       "675        0    1    0      0  \n",
       "878        0    0    0      0  \n",
       "764        0    0    0      0  \n",
       "\n",
       "[668 rows x 464 columns]"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.loc[370:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[125  26]\n",
      " [ 25 115]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.83      0.83       151\n",
      "           1       0.82      0.82      0.82       140\n",
      "\n",
      "    accuracy                           0.82       291\n",
      "   macro avg       0.82      0.82      0.82       291\n",
      "weighted avg       0.82      0.82      0.82       291\n",
      "\n",
      "The accuracy score is 0.8247422680412371\n"
     ]
    }
   ],
   "source": [
    "svclassifier = SVC(kernel='rbf', C=1000)  \n",
    "svclassifier.fit(X_train, y_train) \n",
    "\n",
    "y_pred = svclassifier.predict(X_test)\n",
    "\n",
    "print(confusion_matrix(y_test,y_pred))  \n",
    "print(classification_report(y_test,y_pred)) \n",
    "print(\"The accuracy score is\" + \" \" + str(accuracy_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: \n",
      " 0.7379310344827587 \n",
      "\n",
      "Test score: \n",
      " 0.6460481099656358\n"
     ]
    }
   ],
   "source": [
    "clf = BernoulliNB()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print(f'Train score: \\n {clf.score(X_train, y_train)} \\n')\n",
    "print(f'Test score: \\n {clf.score(X_test, y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## make a correlation matrix"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
